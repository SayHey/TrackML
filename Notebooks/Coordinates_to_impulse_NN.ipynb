{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Coordinate to impulse space Neural Network** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebbok I will attempt to create Neural Network that learns transformation from coordinate to impulse space. \n",
    "\n",
    "Theoretically it should work well for particles that were born in origin.\n",
    "\n",
    "Here is the main notebook where I train the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event\n",
    "\n",
    "# Import keras\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Lambda\n",
    "from keras.initializers import TruncatedNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "data_path = '../Data/generated_data/'\n",
    "x_train_df = pd.read_csv(os.path.join(data_path, \"Coordinates_to_impulse_X.csv\"))\n",
    "y_train_df = pd.read_csv(os.path.join(data_path, \"Coordinates_to_impulse_Y.csv\"))\n",
    "x_train = np.transpose(np.asarray([x_train_df[\"0\"], x_train_df[\"1\"], x_train_df[\"2\"]]))\n",
    "y_train = np.transpose(np.asarray([y_train_df[\"0\"], y_train_df[\"1\"], y_train_df[\"2\"]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1024.59997559 1024.72998047 2955.5       ]\n"
     ]
    }
   ],
   "source": [
    "max_coordinates = np.amax(x_train, axis=0)\n",
    "print(max_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "def model_architecture():\n",
    "    model = Sequential()\n",
    "    \n",
    "    #initializer = TruncatedNormal(stddev=0.1)\n",
    "    \n",
    "    # Normalization layer\n",
    "    # model.add(Lambda(lambda x: x / 1000))\n",
    "    \n",
    "    model.add(Dense(10000, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1))    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X, Y, learning_rate = 0.001, batch_size=1000, epochs=100):   \n",
    "    # Compiling the model\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "    \n",
    "    # Running and evaluating the model\n",
    "    history = model.fit(X, Y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model_check = model_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sanity check data\n",
    "y_check = np.linalg.norm(x_train*1000, axis=1)\n",
    "#y_check = np.sum(x_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "42112/42112 [==============================] - 1s 34us/step - loss: 876533.5680 - mean_absolute_error: 535.0106\n",
      "Epoch 2/100\n",
      "42112/42112 [==============================] - 0s 9us/step - loss: 15001.9288 - mean_absolute_error: 73.4581\n",
      "Epoch 3/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2649.2412 - mean_absolute_error: 31.8232\n",
      "Epoch 4/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2254.7015 - mean_absolute_error: 29.4838\n",
      "Epoch 5/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2274.4744 - mean_absolute_error: 29.6425\n",
      "Epoch 6/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1976.8671 - mean_absolute_error: 27.5140\n",
      "Epoch 7/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2035.0699 - mean_absolute_error: 27.9359\n",
      "Epoch 8/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1889.5130 - mean_absolute_error: 27.2051\n",
      "Epoch 9/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2137.4236 - mean_absolute_error: 29.2002\n",
      "Epoch 10/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1881.9915 - mean_absolute_error: 27.2849\n",
      "Epoch 11/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1841.5306 - mean_absolute_error: 26.9244\n",
      "Epoch 12/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1999.7922 - mean_absolute_error: 28.5403\n",
      "Epoch 13/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1901.5927 - mean_absolute_error: 27.4433\n",
      "Epoch 14/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2136.1804 - mean_absolute_error: 29.5549\n",
      "Epoch 15/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1974.4526 - mean_absolute_error: 27.7357\n",
      "Epoch 16/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 1747.9244 - mean_absolute_error: 26.2292\n",
      "Epoch 17/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2397.9645 - mean_absolute_error: 30.9355\n",
      "Epoch 18/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2353.9470 - mean_absolute_error: 31.5355\n",
      "Epoch 19/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2823.1578 - mean_absolute_error: 34.4914\n",
      "Epoch 20/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2679.1258 - mean_absolute_error: 33.1990\n",
      "Epoch 21/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 4443.1458 - mean_absolute_error: 41.9132\n",
      "Epoch 22/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 6011.8886 - mean_absolute_error: 47.3292\n",
      "Epoch 23/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 10258.9041 - mean_absolute_error: 54.8233\n",
      "Epoch 24/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 16213.7611 - mean_absolute_error: 81.1458\n",
      "Epoch 25/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 47319.6583 - mean_absolute_error: 135.4111\n",
      "Epoch 26/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 70926.9190 - mean_absolute_error: 166.2138\n",
      "Epoch 27/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 15682.8152 - mean_absolute_error: 76.3287\n",
      "Epoch 28/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 2271.3364 - mean_absolute_error: 29.9500\n",
      "Epoch 29/100\n",
      "42112/42112 [==============================] - 0s 9us/step - loss: 1639.9186 - mean_absolute_error: 26.3349\n",
      "Epoch 30/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 8327.0976 - mean_absolute_error: 55.1390\n",
      "Epoch 31/100\n",
      "42112/42112 [==============================] - 0s 8us/step - loss: 23330.9757 - mean_absolute_error: 91.2585\n",
      "Epoch 32/100\n",
      "29000/42112 [===================>..........] - ETA: 0s - loss: 5235.5241 - mean_absolute_error: 43.7427  ETA: 0s - loss: 10137.3166 - mean_absolute_error: 60."
     ]
    }
   ],
   "source": [
    "#model sanity check\n",
    "train_model(model_check, x_train, y_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7771178 ]\n",
      " [2.2212136 ]\n",
      " [2.5904348 ]\n",
      " [0.48731488]\n",
      " [0.52567583]]\n",
      "[1.25467925 1.33604478 1.74684925 0.60350539 0.43044942]\n"
     ]
    }
   ],
   "source": [
    "predict_check = model_check.predict(x_train[0:5], batch_size=5)\n",
    "print(predict_check[0:5])\n",
    "print(y_check[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model for px\n",
    "model_px = train_model(x_train, y_train[:,0], epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model for px\n",
    "model_py = train_model(x_train, y_train[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train model for px\n",
    "model_pz = train_model(x_train, y_train[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim = 10\n",
    "np.set_printoptions(precision=3, suppress = True)\n",
    "predict_px = model_px.predict(x_train[0:lim], batch_size=lim)\n",
    "predict_py = model_py.predict(x_train[0:lim], batch_size=lim)\n",
    "predict_pz = model_pz.predict(x_train[0:lim], batch_size=lim)\n",
    "predict = np.concatenate((predict_px, predict_py, predict_pz), axis=1)\n",
    "print(predict[0:lim])\n",
    "print(y_train[0:lim])\n",
    "#print(x_train[0:lim])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try clustering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "def predict(X, eps=0.01):\n",
    "    cl = DBSCAN(eps, min_samples=1, algorithm='kd_tree')\n",
    "    labels = cl.fit_predict(StandardScaler().fit_transform(X))\n",
    "    return labels\n",
    "\n",
    "#score\n",
    "def create_one_event_submission(event_id, hits, labels):\n",
    "    sub_data = np.column_stack(([event_id]*len(hits), hits.hit_id.values, labels))\n",
    "    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n",
    "    return submission\n",
    "\n",
    "def try_clustering(hits, X):\n",
    "    labels = predict(X)\n",
    "    submission = create_one_event_submission(0, hits, labels)\n",
    "    score = score_event(truth, submission)\n",
    "    print(\"Your score: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../Data/train_100_events/'\n",
    "event_prefix = 'event000001000'\n",
    "hits, cells, particles, truth = load_event(os.path.join(data_path, event_prefix))\n",
    "\n",
    "X = np.transpose([hits.x.values, hits.y.values, hits.z.values])\n",
    "\n",
    "y_predict = model.predict(X, batch_size=10000)\n",
    "\n",
    "try_clustering(hits, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
